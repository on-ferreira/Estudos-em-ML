{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b987a9-f516-43ab-9b77-286757c771e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTransfer Learning - Problema cats x dogs\\nImplementação de rede convolucional usando transfer learning para diferenciação das categorias gato e cachorro.\\n\\nO banco de dados original se encontra aqui. Dentre essas imagens foram separadas 8000 imagens para treinamento e 2000 imagens para teste.\\n\\nTodo o código foi feito no Colab e pode ser compilado online em https://colab.research.google.com.\\n\\n** Autor: Maicon Henrique Cunha**\\n\\nGithub: https://github.com/cunhamaicon\\n\\n!rm -rf catsxdogs\\n\\n!git clone https://github.com/cunhamaicon/catsxdogs\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Transfer Learning - Problema cats x dogs\n",
    "Implementação de rede convolucional usando transfer learning para diferenciação das categorias gato e cachorro.\n",
    "\n",
    "O banco de dados original se encontra aqui. Dentre essas imagens foram separadas 8000 imagens para treinamento e 2000 imagens para teste.\n",
    "\n",
    "Todo o código foi feito no Colab e pode ser compilado online em https://colab.research.google.com.\n",
    "\n",
    "** Autor: Maicon Henrique Cunha**\n",
    "\n",
    "Github: https://github.com/cunhamaicon\n",
    "\n",
    "!rm -rf catsxdogs\n",
    "\n",
    "!git clone https://github.com/cunhamaicon/catsxdogs\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9366b4-1951-4f66-8bc8-01052dd5860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595e50d1-39e1-4028-b386-dbc16477d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CNN - Transfer learning:\n",
    "Importando o modelo MobileNet que foi previamente treinado no ImageNet e descartando a última camada de neurônios:'''\n",
    "\n",
    "model=MobileNet(weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4ae8ec-6125-4181-8063-dbf42a800667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1\n",
      "2 conv1_bn\n",
      "3 conv1_relu\n",
      "4 conv_dw_1\n",
      "5 conv_dw_1_bn\n",
      "6 conv_dw_1_relu\n",
      "7 conv_pw_1\n",
      "8 conv_pw_1_bn\n",
      "9 conv_pw_1_relu\n",
      "10 conv_pad_2\n",
      "11 conv_dw_2\n",
      "12 conv_dw_2_bn\n",
      "13 conv_dw_2_relu\n",
      "14 conv_pw_2\n",
      "15 conv_pw_2_bn\n",
      "16 conv_pw_2_relu\n",
      "17 conv_dw_3\n",
      "18 conv_dw_3_bn\n",
      "19 conv_dw_3_relu\n",
      "20 conv_pw_3\n",
      "21 conv_pw_3_bn\n",
      "22 conv_pw_3_relu\n",
      "23 conv_pad_4\n",
      "24 conv_dw_4\n",
      "25 conv_dw_4_bn\n",
      "26 conv_dw_4_relu\n",
      "27 conv_pw_4\n",
      "28 conv_pw_4_bn\n",
      "29 conv_pw_4_relu\n",
      "30 conv_dw_5\n",
      "31 conv_dw_5_bn\n",
      "32 conv_dw_5_relu\n",
      "33 conv_pw_5\n",
      "34 conv_pw_5_bn\n",
      "35 conv_pw_5_relu\n",
      "36 conv_pad_6\n",
      "37 conv_dw_6\n",
      "38 conv_dw_6_bn\n",
      "39 conv_dw_6_relu\n",
      "40 conv_pw_6\n",
      "41 conv_pw_6_bn\n",
      "42 conv_pw_6_relu\n",
      "43 conv_dw_7\n",
      "44 conv_dw_7_bn\n",
      "45 conv_dw_7_relu\n",
      "46 conv_pw_7\n",
      "47 conv_pw_7_bn\n",
      "48 conv_pw_7_relu\n",
      "49 conv_dw_8\n",
      "50 conv_dw_8_bn\n",
      "51 conv_dw_8_relu\n",
      "52 conv_pw_8\n",
      "53 conv_pw_8_bn\n",
      "54 conv_pw_8_relu\n",
      "55 conv_dw_9\n",
      "56 conv_dw_9_bn\n",
      "57 conv_dw_9_relu\n",
      "58 conv_pw_9\n",
      "59 conv_pw_9_bn\n",
      "60 conv_pw_9_relu\n",
      "61 conv_dw_10\n",
      "62 conv_dw_10_bn\n",
      "63 conv_dw_10_relu\n",
      "64 conv_pw_10\n",
      "65 conv_pw_10_bn\n",
      "66 conv_pw_10_relu\n",
      "67 conv_dw_11\n",
      "68 conv_dw_11_bn\n",
      "69 conv_dw_11_relu\n",
      "70 conv_pw_11\n",
      "71 conv_pw_11_bn\n",
      "72 conv_pw_11_relu\n",
      "73 conv_pad_12\n",
      "74 conv_dw_12\n",
      "75 conv_dw_12_bn\n",
      "76 conv_dw_12_relu\n",
      "77 conv_pw_12\n",
      "78 conv_pw_12_bn\n",
      "79 conv_pw_12_relu\n",
      "80 conv_dw_13\n",
      "81 conv_dw_13_bn\n",
      "82 conv_dw_13_relu\n",
      "83 conv_pw_13\n",
      "84 conv_pw_13_bn\n",
      "85 conv_pw_13_relu\n",
      "86 global_average_pooling2d\n",
      "87 dense\n",
      "88 dense_1\n"
     ]
    }
   ],
   "source": [
    "#Criando a saída do modelo MobileNet:\n",
    "x=model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "#Adicionando uma camada intermediária e a camada final:\n",
    "x=Dense(50,activation='relu')(x)\n",
    "preds=Dense(1,activation='sigmoid')(x) \n",
    "model=Model(inputs=model.input,outputs=preds)\n",
    "#Visualizando todas as camadas da nova rede criada usando o modelo MobileNetV2:\n",
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7cd2ba-030f-445e-8acc-e92cc50a7135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Definindo qual camada da rede será treinada. Nesse caso somente as duas últimas camadas adicionadas:\n",
    "\n",
    "for layer in model.layers[:88]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[88:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "###ImageDataGenerator\n",
    "\n",
    "#Definindo o tamanho de cada batch:\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Cada imagem do banco será apresentada a rede de uma forma diferente através do ImageDataGenerator:\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.4,\n",
    "                                   zoom_range = 0.4,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   rotation_range=50,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('catsxdogs/training_set',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('catsxdogs/test_set',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "270b4859-5898-4169-a21f-83b00dfbeb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 154s 611ms/step - loss: 0.8827 - accuracy: 0.3741 - val_loss: 0.9664 - val_accuracy: 0.3060\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 0.8571 - accuracy: 0.3932 - val_loss: 0.9215 - val_accuracy: 0.3370\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 0.8230 - accuracy: 0.4226 - val_loss: 0.8804 - val_accuracy: 0.3715\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 0.7955 - accuracy: 0.4509 - val_loss: 0.8407 - val_accuracy: 0.4065\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 124s 497ms/step - loss: 0.7675 - accuracy: 0.4728 - val_loss: 0.8043 - val_accuracy: 0.4385\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 126s 504ms/step - loss: 0.7489 - accuracy: 0.4964 - val_loss: 0.7690 - val_accuracy: 0.4725\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 124s 497ms/step - loss: 0.7225 - accuracy: 0.5291 - val_loss: 0.7369 - val_accuracy: 0.5055\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 122s 490ms/step - loss: 0.7025 - accuracy: 0.5494 - val_loss: 0.7054 - val_accuracy: 0.5460\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 120s 481ms/step - loss: 0.6850 - accuracy: 0.5776 - val_loss: 0.6771 - val_accuracy: 0.5820\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 121s 483ms/step - loss: 0.6654 - accuracy: 0.6001 - val_loss: 0.6493 - val_accuracy: 0.6155\n"
     ]
    }
   ],
   "source": [
    "###Treinamento\n",
    "\n",
    "#Definindo os parâmetros de compilação da rede:\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.0001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Fazendo o treinamento da rede:\n",
    "\n",
    "history = model.fit(x=training_set,\n",
    "                   steps_per_epoch=8000/batch_size,\n",
    "                   epochs=10,\n",
    "                   validation_data = test_set,\n",
    "                   validation_steps = 2000/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f907c4-d107-4a6e-abc1-e019265e192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='catsxdogs_mobilenet.h5' target='_blank'>catsxdogs_mobilenet.h5</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\orlan\\OneDrive\\Documentos\\UFF\\DIO\\ML\\catsxdogs_mobilenet.h5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando o modelo para utilização futura:\n",
    "\n",
    "model.save('catsxdogs_mobilenet.h5')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Gerar um link de download para o arquivo\n",
    "FileLink('catsxdogs_mobilenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa9d1be-80ed-48b8-997f-949d53ca02d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat_or_dog_1.jpg', 'cat_or_dog_2.jpg', 'chino1.jpg', 'floyd1.jpg', 'floyd2.jpg', 'floyd3.jpg', 'floyd4.jpg']\n"
     ]
    }
   ],
   "source": [
    "#Previsão\n",
    "\n",
    "#Mostrando os arquivos da pasta single_prediction com imagens inéditas para a rede classificar:\n",
    "\n",
    "import os\n",
    "\n",
    "# Listar os arquivos na pasta single_prediction\n",
    "files = os.listdir('catsxdogs/single_prediction')\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5445e343-87e8-4263-adfb-f081dc228602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escolhendo uma imagem da pasta single_prediction para fazer a previsão:\n",
    "\n",
    "test_image = image.load_img('catsxdogs/single_prediction/floyd1.jpg', target_size = (224, 224))\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image = test_image/255\n",
    "\n",
    "result = model.predict(test_image)\n",
    "\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c064f35-cb28-4aca-a8d0-98937573d0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 0.6493 - accuracy: 0.6205 - val_loss: 0.6234 - val_accuracy: 0.6550\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 124s 497ms/step - loss: 0.6296 - accuracy: 0.6415 - val_loss: 0.5996 - val_accuracy: 0.6835\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 120s 481ms/step - loss: 0.6161 - accuracy: 0.6589 - val_loss: 0.5767 - val_accuracy: 0.7120\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 118s 471ms/step - loss: 0.6018 - accuracy: 0.6883 - val_loss: 0.5553 - val_accuracy: 0.7390\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 118s 473ms/step - loss: 0.5873 - accuracy: 0.6966 - val_loss: 0.5356 - val_accuracy: 0.7645\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 118s 474ms/step - loss: 0.5780 - accuracy: 0.7039 - val_loss: 0.5174 - val_accuracy: 0.7830\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 117s 470ms/step - loss: 0.5620 - accuracy: 0.7266 - val_loss: 0.4994 - val_accuracy: 0.7965\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 119s 476ms/step - loss: 0.5516 - accuracy: 0.7399 - val_loss: 0.4828 - val_accuracy: 0.8115\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 118s 472ms/step - loss: 0.5412 - accuracy: 0.7486 - val_loss: 0.4680 - val_accuracy: 0.8185\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 120s 480ms/step - loss: 0.5312 - accuracy: 0.7499 - val_loss: 0.4528 - val_accuracy: 0.8320\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 118s 473ms/step - loss: 0.5223 - accuracy: 0.7634 - val_loss: 0.4400 - val_accuracy: 0.8415\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 117s 469ms/step - loss: 0.5132 - accuracy: 0.7651 - val_loss: 0.4272 - val_accuracy: 0.8530\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 118s 470ms/step - loss: 0.5040 - accuracy: 0.7755 - val_loss: 0.4154 - val_accuracy: 0.8625\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 119s 476ms/step - loss: 0.4973 - accuracy: 0.7785 - val_loss: 0.4044 - val_accuracy: 0.8670\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 119s 474ms/step - loss: 0.4870 - accuracy: 0.7886 - val_loss: 0.3941 - val_accuracy: 0.8725\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 118s 471ms/step - loss: 0.4873 - accuracy: 0.7885 - val_loss: 0.3835 - val_accuracy: 0.8755\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 117s 467ms/step - loss: 0.4763 - accuracy: 0.7921 - val_loss: 0.3746 - val_accuracy: 0.8815\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 117s 469ms/step - loss: 0.4664 - accuracy: 0.8040 - val_loss: 0.3660 - val_accuracy: 0.8840\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 117s 469ms/step - loss: 0.4610 - accuracy: 0.8048 - val_loss: 0.3572 - val_accuracy: 0.8875\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 118s 471ms/step - loss: 0.4533 - accuracy: 0.8104 - val_loss: 0.3498 - val_accuracy: 0.8895\n"
     ]
    }
   ],
   "source": [
    "#A accúracia do modelo ainda está muito baixa, vou treinar por mais 10 epochs\n",
    "\n",
    "# Carregar o modelo salvo (caso você tenha fechado o notebook e deseje carregar novamente o modelo)\n",
    "from keras.models import load_model\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "model = load_model('catsxdogs_mobilenet.h5')\n",
    "\n",
    "# Definir o número total de epochs desejado (10 anteriores + 10 adicionais)\n",
    "total_epochs = 20\n",
    "\n",
    "# Continuar o treinamento do modelo\n",
    "history = model.fit(x=training_set,\n",
    "                    steps_per_epoch=8000/batch_size,\n",
    "                    epochs=total_epochs,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=2000/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13d79110-cf8a-4723-950f-55940d6ad1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo para utilização futura:\n",
    "\n",
    "model.save('catsxdogsv30_mobilenet.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1df3fec-b009-453c-8d96-4cd44ce1c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Refazendo os testes\n",
    "\n",
    "#Escolhendo uma imagem da pasta single_prediction para fazer a previsão:\n",
    "\n",
    "test_image = image.load_img('catsxdogs/single_prediction/cat_or_dog_1.jpg', target_size = (224, 224))\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image = test_image/255\n",
    "\n",
    "result = model.predict(test_image)\n",
    "\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
